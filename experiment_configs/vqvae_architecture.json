{
    "commit_coefficient": 0.25, // could be in the range 0.1-2.0
    "learning_rate": 0.001,
    "encoder": {
        "kernel_sizes": [7, 7, 7, 7, 7],
        "strides": [3, 3, 3, 3, 3],
        "num_residual_channels": [16, 32, 64, 128, 256]
    },
    "vq": {
        "latent_dim": 128, // What should the latent dimension be?
        "num_latent": 512
    },
    "generator": {
        "kernel_sizes": [7, 7, 7, 7, 7],
        "strides": [3, 3, 3, 3, 3],
        // TODO: Check receptive field, maybe use dilations? 
        // TODO: choose the out_paddings once we know the length of our samples from VCTK
        "out_paddings": [0, 1, 1, 1, 0], // output = (input -1)*s - 2*padding + kernel + output_padding 
        "num_residual_channels": [128, 64, 32, 16, 1],
        "speaker_dim": 60 // What should be the dimensionality for speaker codes?
    }
}