@article{Abe1990,
  title={Voice conversion through vector quantization},
  author={Abe, Masanobu and Nakamura, Satoshi and Shikano, Kiyohiro and Kuwabara, Hisao},
  journal={Journal of the Acoustical Society of Japan (E)},
  volume={11},
  number={2},
  pages={71--76},
  year={1990},
  publisher={Acoustical Society of Japan}
}

@article{Arjovsky2017,
  title={Wasserstein gan},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  journal={arXiv preprint arXiv:1701.07875},
  year={2017}
}

@article{arjovsky2017towards,
  title={Towards principled methods for training generative adversarial networks},
  author={Arjovsky, Martin and Bottou, L{\'e}on},
  journal={arXiv preprint arXiv:1701.04862},
  year={2017}
}

@article{Makhzani2015,
  title={Adversarial autoencoders},
  author={Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
  journal={arXiv preprint arXiv:1511.05644},
  year={2015}
}

@misc{yamagishi_english_2012,
	title = {English multi-speaker corpus for {CSTR} voice cloning toolkit},
	url = {http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html},
	author = {Yamagishi, Junichi},
	year = {2012}
}

@article{Lorenzo2018,
  title={The voice conversion challenge 2018: Promoting development of parallel and nonparallel methods},
  author={Lorenzo-Trueba, Jaime and Yamagishi, Junichi and Toda, Tomoki and Saito, Daisuke and Villavicencio, Fernando and Kinnunen, Tomi and Ling, Zhenhua},
  journal={arXiv preprint arXiv:1804.04262},
  year={2018}
}

@article{Hsu2017,
abstract = {Building a voice conversion (VC) system from non-parallel speech corpora is challenging but highly valuable in real application scenarios. In most situations, the source and the target speakers do not repeat the same texts or they may even speak different languages. In this case, one possible, although indirect, solution is to build a generative model for speech. Generative models focus on explaining the observations with latent variables instead of learning a pairwise transformation function, thereby bypassing the requirement of speech frame alignment. In this paper, we propose a non-parallel VC framework with a variational autoencoding Wasserstein generative adversarial network (VAW-GAN) that explicitly considers a VC objective when building the speech model. Experimental results corroborate the capability of our framework for building a VC system from unaligned data, and demonstrate improved conversion quality.},
archivePrefix = {arXiv},
arxivId = {arXiv:1704.00849v3},
author = {Hsu, Chin-cheng and Hwang, Hsin-te and Wu, Yi-chiao and Tsao, Yu and Wang, Hsin-min},
eprint = {arXiv:1704.00849v3},
keywords = {Audio,MLP},
mendeley-tags = {Audio,MLP},
number = {2},
title = {{Voice Conversion from Unaligned Corpora using Variational Autoencoding Wasserstein Generative Adversarial Networks}},
year = {2017}
}

@article{Karras2018,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  journal={arXiv preprint arXiv:1812.04948},
  year={2018}
}


@inproceedings{Larsen2015,
abstract = {We present an autoencoder that leverages learned representations to better measure similarities in data space. By combining a variational autoencoder with a generative adversarial network we can use learned feature representations in the GAN discriminator as basis for the VAE reconstruction objective. Thereby, we replace element-wise errors with feature-wise errors to better capture the data distribution while offering invariance towards e.g. translation. We apply our method to images of faces and show that it outperforms VAEs with element-wise similarity measures in terms of visual fidelity. Moreover, we show that the method learns an embedding in which high-level abstract visual features (e.g. wearing glasses) can be modified using simple arithmetic.},
archivePrefix = {arXiv},
arxivId = {arXiv:1512.09300v2},
author = {Larsen, Anders Boesen Lindbo and S{\o}nderby, S{\o}ren Kaae and Larochelle, Hugo and Winther, Ole},
booktitle = {Proceedings of International Conference on Machine Learning (ICML)},
eprint = {arXiv:1512.09300v2},
keywords = {GAN,MLP},
mendeley-tags = {GAN,MLP},
title = {{Autoencoding beyond pixels using a learned similarity metric}},
year = {2015}
}
@inproceedings{VandenOord2017,
abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of “posterior collapse” - where the latents are ignored when they are paired with a powerful autoregressive decoder - typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
archivePrefix = {arXiv},
arxivId = {arXiv:1711.00937v2},
author = {van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
booktitle = {Proceedings of Neural Information Processing Systems (NIPS 2017)},
eprint = {arXiv:1711.00937v2},
file = {:home/vaidas/Downloads/1711.00937.pdf:pdf},
keywords = {MLP},
mendeley-tags = {MLP},
title = {{Neural Discrete Representation Learning}},
year = {2017}
}
@article{Oord2016,
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
archivePrefix = {arXiv},
arxivId = {1609.03499},
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
eprint = {1609.03499},
keywords = {Audio,Convolution,MLP,Neural Nets},
mendeley-tags = {Audio,Convolution,MLP,Neural Nets},
month = {sep},
title = {{WaveNet: A Generative Model for Raw Audio}},
url = {http://arxiv.org/abs/1609.03499},
year = {2016}
}
@incollection{Kreiman2011,
author = {Kreiman, Jody and Sidtis, Diana},
booktitle = {Foundations of Voice Studies: An Interdisciplinary Approach to Voice Production and Perception},
chapter = {1},
doi = {10.1002/9781444395068},
isbn = {9781444395068},
keywords = {MLP},
mendeley-tags = {MLP},
publisher = {John Wiley {\&} Sons},
title = {{Foundations of Voice Studies: Introduction}},
year = {2011}
}
@article{Kingma2013,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114},
journal = {arXiv e-prints},
keywords = {IRR},
mendeley-tags = {IRR},
month = {dec},
pages = {arXiv:1312.6114},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2013}
}
@inproceedings{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {1406.2661},
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems 27 (NIPS 2014)},
eprint = {1406.2661},
keywords = {GAN,IRR,MLP},
mendeley-tags = {GAN,IRR,MLP},
month = {jun},
title = {{Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1406.2661},
year = {2014}
}
@article{Bengio2013,
abstract = {Stochastic neurons and hard non-linearities can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic or non-smooth neurons? I.e., can we “back-propagate” through these stochastic neurons? We examine this question, existing approaches, and compare four families of solutions, applicable in different settings. One of them is the minimum variance unbiased gradient estimator for stochatic binary neurons (a special case of the REINFORCE algorithm). A second approach, introduced here, decomposes the operation of a binary stochastic neuron into a stochastic binary part and a smooth differentiable part, which approximates the expected effect of the pure stochatic binary neuron to first order. A third approach involves the injection of additive or multiplicative noise in a computational graph that is otherwise differentiable. A fourth approach heuristically copies the gradient with respect to the stochastic output directly as an estimator of the gradient with respect to the sigmoid argument (we call this the straight-through estimator). To explore a context where these estimators are useful, we consider a small-scale version of conditional computation, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the neural network. In this case, it is important that the gating units produce an actual 0 most of the time. The resulting sparsity can be potentially be exploited to greatly reduce the computational cost of large deep networks for which conditional computation would be useful.},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.3432v1},
author = {Bengio, Yoshua and Nicholas, Leonard and Courville, Aaron},
eprint = {arXiv:1308.3432v1},
keywords = {MLP},
mendeley-tags = {MLP},
pages = {1--12},
title = {{Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation}},
year = {2013}
}

@inproceedings{Vondrick2016,
  title={Generating videos with scene dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle={Advances In Neural Information Processing Systems},
  pages={613--621},
  year={2016}
}